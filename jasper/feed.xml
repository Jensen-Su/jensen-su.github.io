<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Firefly In The Darkness, Flittering About - Articles</title>
    <description>Doubt thout the stars are fire, Doubt that the sun doth move, Doubt truth to be a liar, But never doubt the lights</description>
    <link>
    http://jensen-su.github.io/jasper/</link>
    
      
      <item>
        <title>Notes on SVM</title>
        
          <description>&lt;p&gt;$~$&lt;/p&gt;

</description>
        
        <pubDate>Fri, 05 Aug 2016 18:10:00 +0800</pubDate>
        <link>
        http://jensen-su.github.io/jasper//notes-on-svm</link>
        <guid isPermaLink="true">http://jensen-su.github.io/jasper//notes-on-svm</guid>
      </item>
      
    
      
      <item>
        <title>The Learning Theroy</title>
        
          <description>&lt;p&gt;$~$&lt;/p&gt;

</description>
        
        <pubDate>Sat, 30 Jul 2016 18:10:00 +0800</pubDate>
        <link>
        http://jensen-su.github.io/jasper//learning-theory</link>
        <guid isPermaLink="true">http://jensen-su.github.io/jasper//learning-theory</guid>
      </item>
      
    
      
      <item>
        <title>The Gradient Descent</title>
        
          <description>&lt;p&gt; &lt;/p&gt;
&lt;p&gt; The cover picture is taken from Michael Nielsen&#39;s book 
&lt;a href=&quot;http://neuralnetworksanddeeplearning.com/index.html&quot;&gt;&lt;em&gt; Neural Networks and Deep Learning&lt;/em&gt;.
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_descent&quot;&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt;&lt;/a&gt;, 
also known as &lt;em&gt;steepest descent&lt;/em&gt;, is a first-order optimization algorithm mostly used to 
find a local minimum of a given contunious, differentiable function. For convex functions,
the local minimum is also the global minimum. Therefore gradient descent is widely used 
to solve the unconstrained optimization problem. One of its versions is also the most commonly 
used algorithm to train the neural networks in deep learning.
&lt;/p&gt;

</description>
        
        <pubDate>Mon, 11 Jul 2016 18:10:00 +0800</pubDate>
        <link>
        http://jensen-su.github.io/jasper//gradient-descent</link>
        <guid isPermaLink="true">http://jensen-su.github.io/jasper//gradient-descent</guid>
      </item>
      
    
      
      <item>
        <title>My First Post</title>
        
          <description>&lt;p&gt; Hello world, this is my first post. &lt;/p&gt;

</description>
        
        <pubDate>Sun, 10 Jul 2016 18:10:00 +0800</pubDate>
        <link>
        http://jensen-su.github.io/jasper//my-first-post</link>
        <guid isPermaLink="true">http://jensen-su.github.io/jasper//my-first-post</guid>
      </item>
      
    
      
      <item>
        <title>A Full and Comprehensive Style Test</title>
        
          <description>&lt;p&gt;This is just an &lt;em&gt;ipsis verbis&lt;/em&gt; copy of the first example running on the &lt;a href=&quot;http://demo.ghost.io&quot;&gt;Ghost Demo&lt;/a&gt;. This shows how you can use html styling to achieve your hopes.&lt;/p&gt;

</description>
        
        <pubDate>Sat, 27 Sep 2014 18:18:00 +0800</pubDate>
        <link>
        http://jensen-su.github.io/jasper//a-full-and-comprehensive-style-test</link>
        <guid isPermaLink="true">http://jensen-su.github.io/jasper//a-full-and-comprehensive-style-test</guid>
      </item>
      
    
  </channel>
</rss>
